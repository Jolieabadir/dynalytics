# Dynalytics

Extract and analyze climbing movement from video using computer vision.

Dynalytics processes climbing videos to extract pose data, track body position, and calculate joint angles ‚Äî building a foundation for movement analysis and ML training.

## Who is this for?

- **Athletes** looking to analyze and improve their movement patterns
- **Researchers** exploring biomechanics and movement optimization/or injury prevention

## Vision

Dynalytics uses a **personalized model architecture**:

```
Base Model (trained on many climbers)
         ‚Üì
    Generic "good form" knowledge
         ‚Üì
User uploads their videos
         ‚Üì
Fine-tuned Personal Model
         ‚Üì
    Learns YOUR body, YOUR style
```

The base model provides immediate value from day one, while personal data fine-tunes recommendations to each climber's unique body type, flexibility, and style.

## Features

### Current (Phase 1)
- ‚úÖ Pose estimation and body tracking
- ‚úÖ Joint angle calculation (12 angles per frame)
- ‚úÖ Velocity and speed tracking (center of mass + all landmarks)
- ‚úÖ Export data to CSV for analysis
- ‚úÖ Live visualization with skeleton overlay and angle display

### Planned
- [ ] Data collection UI
- [ ] Rules engine for form feedback
- [ ] Move classification (lock-off, deadpoint, dyno, etc.)
- [ ] ML-based movement predictions
- [ ] Imbalance and injury risk detection

## Tracked Angles

| Angle | Points | What it measures |
|-------|--------|------------------|
| Left elbow | shoulder ‚Üí elbow ‚Üí wrist | Arm bend |
| Right elbow | shoulder ‚Üí elbow ‚Üí wrist | Arm bend |
| Left shoulder | hip ‚Üí shoulder ‚Üí elbow | Arm raise relative to torso |
| Right shoulder | hip ‚Üí shoulder ‚Üí elbow | Arm raise relative to torso |
| Left hip | shoulder ‚Üí hip ‚Üí knee | Leg position relative to torso |
| Right hip | shoulder ‚Üí hip ‚Üí knee | Leg position relative to torso |
| Left knee | hip ‚Üí knee ‚Üí ankle | Leg bend |
| Right knee | hip ‚Üí knee ‚Üí ankle | Leg bend |
| Left ankle | knee ‚Üí ankle ‚Üí heel | Foot flex |
| Right ankle | knee ‚Üí ankle ‚Üí heel | Foot flex |
| Upper back | left shoulder ‚Üí shoulder midpoint ‚Üí right shoulder | Shoulder hunch/openness |
| Lower back | shoulder midpoint ‚Üí hip midpoint ‚Üí knee midpoint | Torso arch/round |

## Tech Stack

- Python
- OpenCV
- MediaPipe
- TensorFlow

## Project Structure

```
dynalytics/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ landmark.py         # Landmark class (x, y, visibility)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ angle.py            # Angle class (3 points ‚Üí degrees)
‚îÇ   ‚îú‚îÄ‚îÄ pose/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ estimator.py        # PoseEstimator class (wraps MediaPipe)
‚îÇ   ‚îú‚îÄ‚îÄ analysis/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ joint_analyzer.py   # JointAnalyzer class (calculates all 12 angles)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ frame_data.py       # FrameData class (holds all data for one frame)
‚îÇ   ‚îú‚îÄ‚îÄ export/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ csv_exporter.py     # CSVExporter class
‚îÇ   ‚îî‚îÄ‚îÄ config/
‚îÇ       ‚îî‚îÄ‚îÄ settings.py         # Settings class (thresholds, constants)
‚îú‚îÄ‚îÄ tests/
‚îú‚îÄ‚îÄ data/                       # Output CSVs (gitignored)
‚îú‚îÄ‚îÄ videos/                     # Input videos (gitignored)
‚îú‚îÄ‚îÄ main.py                     # Main analysis script
‚îú‚îÄ‚îÄ visualizer_live.py          # Live video player with pose overlay
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

## Installation

```bash
git clone https://github.com/jolieabadir/dynalytics.git
cd dynalytics
python3.11 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

> Note: Requires Python 3.11 (MediaPipe doesn't support 3.13+ yet)

## Usage

### Step 1: Extract Pose Data

```bash
# Basic usage - outputs angles and speeds to CSV
python main.py path/to/video.mov

# Include raw landmark positions (required for visualization)
python main.py path/to/video.mov --landmarks

# Specify output path
python main.py path/to/video.mov --output my_data.csv
```

### Step 2: Visualize Results

After extracting pose data with landmarks, you can view it with a live overlay:

```bash
# Play video with skeleton and angle overlay
python visualizer_live.py path/to/video.mov data/video.csv
```

**Visualization Controls:**
- **SPACE** - Pause/Resume
- **Q** - Quit
- **‚Üí** - Skip forward 10 frames
- **‚Üê** - Rewind 10 frames

**Visualization Features:**
- üü¢ Green skeleton connecting body joints
- üü° Yellow circles on joint points
- üìä Real-time angle display (6 key angles)
- üé® Color-coded speed indicator (low/med/high)

**Options:**
```bash
# Play at 2x speed
python visualizer_live.py video.mov data.csv --speed 2.0

# Hide specific elements
python visualizer_live.py video.mov data.csv --no-skeleton
python visualizer_live.py video.mov data.csv --no-angles
python visualizer_live.py video.mov data.csv --no-speed
```

## Complete Workflow Example

```bash
# 1. Extract pose data with landmarks
python main.py videos/climb.mp4 --landmarks

# 2. View results with live visualization
python visualizer_live.py videos/climb.mp4 data/climb.csv

# 3. Analyze CSV data in your favorite tool (Excel, Python, etc.)
```

## Data Output

The CSV export includes:
- **Frame metadata**: frame number, timestamp
- **12 joint angles**: elbow, knee, shoulder, hip, ankle, upper/lower back
- **Landmark speeds**: individual joint movement speeds
- **Center of mass metrics**: velocity (x, y) and speed
- **Key landmark velocities**: wrists and hips (x, y components)

## Data Pipeline

```
Raw Video
    ‚Üì
Dynalytics (pose extraction)
    ‚Üì
Raw Angles + Speeds CSV     ‚Üê Current phase
    ‚Üì
+ Rules / Labels
    ‚Üì
Labeled Data CSV
    ‚Üì
ML Training
    ‚Üì
Predictions
```

## License

MIT

---

Development by [@jolieabadir](https://github.com/jolieabadir)